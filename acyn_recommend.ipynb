{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "acyn_recommend",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB_15mrn5PGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "c5fbcfb5-68e0-47bd-b09f-d817ace5acab"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 23.7MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.6MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: beautifulsoup4, colorama, JPype1, tweepy, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eeMIErDxpZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 토큰화를 위한 모듈\n",
        "from konlpy.tag import Okt\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "pd.set_option('display.max_columns', 2000)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "# 네이버 웹툰 가져오기\n",
        "naver_wt = pd.read_csv('./drive/My Drive/acyn/naver_webtoon.csv', delimiter = '\\t', header=None, encoding='utf-8')\n",
        "naver_wt = pd.DataFrame({'name' : naver_wt[0].str.split(',').str[0], 'intro' : naver_wt[0] }, columns = ['name', 'intro'])\n",
        "\n",
        "# 다음 웹툰 가져오기\n",
        "daum_wt = pd.read_csv('./drive/My Drive/acyn/daum_webtoon.csv', delimiter = '\\t', header=None, encoding='utf-8')\n",
        "daum_wt = pd.DataFrame({'name' : daum_wt[0].str.split(',').str[0], 'intro' : daum_wt[0]}, columns = ['name', 'intro'])\n",
        "\n",
        "# 네이버 웹소설 가져오기\n",
        "naver_nvl = pd.read_csv('./drive/My Drive/acyn/naver_novel.csv', header=None, encoding='utf-8')\n",
        "naver_nvl = pd.DataFrame({'name' : naver_nvl[0], 'intro' : naver_nvl[1]}, columns = ['name', 'intro'])\n",
        "\n",
        "# 넷플릭스 가져오기\n",
        "netflix = pd.read_csv('./drive/My Drive/acyn/netflix.csv')\n",
        "netflix = netflix.dropna(axis=0)\n",
        "netflix = netflix.drop(['Unnamed: 0'], axis=1)\n",
        "netflix_plot = netflix['netflix']\n",
        "\n",
        "# stopword 제거\n",
        "sw = ['.', ',', '\"','\"&', '\"\"\"','\\n', '이', '가', '을', '를', '는', '은', '과', '의', '로','에서','에', '도','에게','와', '인']\n",
        "\n",
        "# 네이버 웹툰 토큰화 및 stopword 제거\n",
        "for intro_num in range(len(naver_wt.intro)):\n",
        "    words = re.compile(\"[^\\w]\").sub(' ', naver_wt.intro[intro_num])\n",
        "    words = Okt().morphs(words)\n",
        "    sw_removed = []\n",
        "    for i in words:\n",
        "       if i.lower() not in sw:\n",
        "           sw_removed.append(i)\n",
        "    naver_wt.intro[intro_num] = sw_removed\n",
        "\n",
        "# 다음 웹툰 토큰화 및 stopword 제거\n",
        "for intro_num in range(len(daum_wt.intro)):\n",
        "    words = re.compile(\"[^\\w]\").sub(' ', daum_wt.intro[intro_num])\n",
        "    words = Okt().morphs(words)\n",
        "    sw_removed = []\n",
        "    for i in words:\n",
        "       if i.lower() not in sw:\n",
        "           sw_removed.append(i)\n",
        "    daum_wt.intro[intro_num] = sw_removed\n",
        "\n",
        "# 네이버 웹소설 토큰화 및 stopword 제거\n",
        "for intro_num in range(len(naver_nvl.intro)):\n",
        "    words = re.compile(\"[^\\w]\").sub(' ', naver_nvl.intro[intro_num])\n",
        "    words = Okt().morphs(words)\n",
        "    sw_removed = []\n",
        "    for i in words:\n",
        "       if i.lower() not in sw:\n",
        "           sw_removed.append(i)\n",
        "    naver_nvl.intro[intro_num] = sw_removed\n",
        "\n",
        "# 넷플릭스 토큰화 및 stopword 제거\n",
        "toknized_plots_list = []\n",
        "for plot in netflix_plot:\n",
        "  words_list_for_one_plot = Okt().morphs(plot)\n",
        "  sw_removed = []\n",
        "  for i in words_list_for_one_plot:\n",
        "      if i.lower() not in sw:\n",
        "          sw_removed.append(i)\n",
        "  toknized_plots_list.append(sw_removed)\n",
        "  \n",
        "netflix[\"tokenized_plot\"] = toknized_plots_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jKB0N3G6sJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "0d1c4ea0-1e85-467b-a391-88f271fc3561"
      },
      "source": [
        "# 사용자 입력받기\n",
        "input_wd = input()\n",
        "\n",
        "naver_wt_recommend = []\n",
        "daum_wt_recommend = []\n",
        "naver_nvl_recommend = []\n",
        "netflix_recommend = []\n",
        "\n",
        "# 네이버 웹툰에서 입력 관련 컨텐츠 뽑기\n",
        "for intro_num in range(len(naver_wt.intro)):\n",
        "    if input_wd in naver_wt.intro[intro_num] :\n",
        "        naver_wt_recommend.append(naver_wt.name[intro_num])\n",
        "\n",
        "# 다음 웹툰에서 입력 관련 컨텐츠 뽑기\n",
        "for intro_num in range(len(daum_wt.intro)):\n",
        "    if input_wd in daum_wt.intro[intro_num] :\n",
        "        daum_wt_recommend.append(daum_wt.name[intro_num])\n",
        "\n",
        "# 네이버 웹소설에서 입력 관련 컨텐츠 뽑기\n",
        "for intro_num in range(len(naver_nvl.intro)):\n",
        "    if input_wd in naver_nvl.intro[intro_num] :\n",
        "        naver_nvl_recommend.append(naver_nvl.name[intro_num])\n",
        "\n",
        "# 넷플릭스에서 입력 관련 컨텐츠 뽑기\n",
        "for video in netflix.iterrows():\n",
        "  tokenized = video[1][5]\n",
        "  for word in tokenized:\n",
        "      if word == input_wd:\n",
        "        netflix_recommend.append(video[1][1])\n",
        "\n",
        "print(\"추천 네이버 웹툰 :\",naver_wt_recommend)\n",
        "print(\"추천 다음 웹툰 :\",daum_wt_recommend)\n",
        "print(\"추천 네이버 웹소설 :\", naver_nvl_recommend)\n",
        "print(\"추천 넷플릭스 : \", netflix_recommend)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학교\n",
            "추천 네이버 웹툰 : ['인생존망', '야자괴담', '럭키언럭키', '셧업앤댄스', '커피도둑', '소녀재판', '학교정벌', '신이 담긴 아이', '만찢남녀', 'Here U Are']\n",
            "추천 다음 웹툰 : ['아싸가 알아버렸다', '이대로 멈출 순 없다', '학교대표', '우리학교 김선생님']\n",
            "추천 네이버 웹소설 : ['아기가 생겼어요', '표류전쟁', '납치 감금에서 시작되는 우리들의 사바트']\n",
            "추천 넷플릭스 :  ['꼴찌 마녀 밀드레드', 'The Principal', '학교생활', '핑키 멀링키', '보고싶다', '러브포텐: 순정의 시대', '러브 라이브! School idol project', '요리고교생', '카케구루이', '그린하우스 아카데미', '굿모닝 콜', '걸즈 앤 판처', '그녀의 이름은 난노', '에버 애프터 하이', '엘리트들', '샤를로트', '백스테이지', '선생 김봉두', '가질 수 있다면', '여고괴담 두번째 이야기', '여고괴담 4: 목소리', '트윈스터즈', '협객 소걸아', '더 리허설', '아웃사이더', '루저의 역습', '뉴 가이', '뉴 가이', '키싱 부스', '크래프트', '설득의 신', '로미나', '칠소복', '칠소복', 'Nothing in Return', '네버 렛 미 고', '노바: 미래의 학교', '아적야만동학: 거친 녀석들', '아적야만동학: 거친 녀석들', '아적야만동학: 거친 녀석들', '기적의 학교', '맥팔랜드 USA', '너의 췌장을 먹고 싶어', '나는 거인들을 죽인다', '허리케인 비앙카', '사냥의 계절', '신부님은 골키퍼', '우정의 조건', '한공주', '폴른: 추락천사', '엔더스 게임', '이모 더 뮤지컬', '돈 크라이 마미', '디태치먼트', '조폐국 침입 프로젝트', '코치 카터', '캐리', '브루노와 부츠: 수영장을 부탁해', '블루 마운틴 스테이트: 더 라이즈 오브 사드랜드', \"바비와 동생들이 함께하는 '포니 테일'\", '합격!', '봄의 멜로디', '내가 널 사랑할 수 없는 10가지 이유', '희망의 딸들', '지상의 별처럼', '페리스의 해방', '사관과 신사', '더 이상 참을 수 없어', '감옥학원', '오, 라모나!', '내안의 그놈', '스파이더맨: 파 프롬 홈', '인간수업', '인간수업']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}